{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a61ece00-2cfb-4209-be4a-422d3754d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d33e6e8-39e9-498d-b4fc-41d33251ae59",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dddbd07-4303-4b05-8c93-4a11eb08395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Loads the dataset from a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: Path to the dataset file.\n",
    "    \n",
    "    Returns:\n",
    "    - dataset: Loaded dataset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dataset = pd.read_csv(file_path)\n",
    "        return dataset\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d9f7b1-cfcd-4268-9f10-b02c3ab76046",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd8b4b65-d0ed-489c-af59-f49595d368bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dataset):\n",
    "    \"\"\"\n",
    "    Preprocesses the data by checking for missing values and scaling.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset: Dataset to preprocess.\n",
    "    \n",
    "    Returns:\n",
    "    - dataset: Preprocessed dataset.\n",
    "    \"\"\"\n",
    "    # Check for missing values\n",
    "    print(\"Missing values count:\")\n",
    "    print(dataset.isna().sum())\n",
    "    \n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    numerical_cols = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
    "    dataset[numerical_cols] = scaler.fit_transform(dataset[numerical_cols])\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9720283a-ceb2-4f53-9f39-626685287280",
   "metadata": {},
   "source": [
    "### Split data into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ee2dcf3-73e6-48e2-b87c-3b20f613a638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataset):\n",
    "    \"\"\"\n",
    "    Splits the dataset into features (X) and target (y).\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset: Dataset to split.\n",
    "    \n",
    "    Returns:\n",
    "    - X: Features.\n",
    "    - y: Target variable.\n",
    "    \"\"\"\n",
    "    X = dataset.drop(['Class'], axis=1)\n",
    "    y = dataset['Class']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066c9bea-debe-4177-8594-cc2dc5a9c712",
   "metadata": {},
   "source": [
    "#### Train and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "889576dc-daa4-4c8a-abca-b8b7a2ba06e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Trains a Random Forest classifier and evaluates its performance.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: Training features.\n",
    "    - X_test: Testing features.\n",
    "    - y_train: Training target.\n",
    "    - y_test: Testing target.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Apply SMOTE to balance the training set\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train a Random Forest classifier\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(X_train_balanced, y_train_balanced)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    # Evaluate model performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1:.3f}, AUC-ROC: {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef35b5-e3d6-4344-9f44-9564723d0972",
   "metadata": {},
   "source": [
    "#### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5cdd49c-ffde-4b84-b642-2b92dfef36af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values count:\n",
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "Accuracy: 1.000, Precision: 0.882, Recall: 0.837, F1-score: 0.859, AUC-ROC: 0.975\n"
     ]
    }
   ],
   "source": [
    "# Main function\n",
    "def main():\n",
    "    file_path = 'creditcard.csv'  # Update with your dataset path\n",
    "    dataset = load_data(file_path)\n",
    "    \n",
    "    # Preprocess data\n",
    "    dataset = preprocess_data(dataset)\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    X, y = split_data(dataset)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train and evaluate model\n",
    "    train_and_evaluate(X_train, X_test, y_train, y_test)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
